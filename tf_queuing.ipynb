{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN47OS1Zbr9DSDA4ju0neWb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jieunlim/TensorflowTest2022/blob/main/tf_queuing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGas_wrc7WB3",
        "outputId": "cb9fc3c2-0e4c-4bfe-9d37-cfe912e6aa2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def FIFO_queue_demo_no_coord():\n",
        "    # first let's create a simple random normal Tensor to act as dummy input data\n",
        "    # this operation should be run more than once, everytime the queue needs filling\n",
        "    # back up.  However, it isn't in this case, because of our lack of a co-ordinator/\n",
        "    # proper threading\n",
        "    dummy_input = tf.random_normal([3], mean=0, stddev=1)\n",
        "    # let's print so we can see when this operation is called\n",
        "    dummy_input = tf.Print(dummy_input, data=[dummy_input],\n",
        "                           message='New dummy inputs have been created: ', summarize=6)\n",
        "    # create a FIFO queue object\n",
        "    q = tf.FIFOQueue(capacity=3, dtypes=tf.float32)\n",
        "    # load up the queue with our dummy input data\n",
        "    enqueue_op = q.enqueue_many(dummy_input)\n",
        "    # grab some data out of the queue\n",
        "    data = q.dequeue()\n",
        "    # now print how much is left in the queue\n",
        "    data = tf.Print(data, data=[q.size()], message='This is how many items are left in q: ')\n",
        "    # create a fake graph that we can call upon\n",
        "    fg = data + 1\n",
        "    # now run some operations\n",
        "    with tf.Session() as sess:\n",
        "        # first load up the queue\n",
        "        sess.run(enqueue_op)\n",
        "        # now dequeue a few times, and we should see the number of items\n",
        "        # in the queue decrease\n",
        "        sess.run(fg)\n",
        "        sess.run(fg)\n",
        "        sess.run(fg)\n",
        "        # by this stage the queue will be emtpy, if we run the next time, the queue\n",
        "        # will block waiting for new data\n",
        "        sess.run(fg)\n",
        "        # this will never print:\n",
        "        print(\"We're here!\")"
      ],
      "metadata": {
        "id": "VnmJD1p-1785"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FIFO_queue_demo_with_coord():\n",
        "    # first let's create a simple random normal Tensor to act as dummy input data\n",
        "    # this operation should be run more than once, everytime the queue needs filling\n",
        "    # back up.  However, it isn't in this case, because of our lack of a co-ordinator/\n",
        "    # proper threading\n",
        "    dummy_input = tf.random_normal([5], mean=0, stddev=1)\n",
        "    # let's print so we can see when this operation is called\n",
        "    dummy_input = tf.Print(dummy_input, data=[dummy_input],\n",
        "                           message='New dummy inputs have been created: ', summarize=6)\n",
        "    # create a FIFO queue object\n",
        "    q = tf.FIFOQueue(capacity=3, dtypes=tf.float32)\n",
        "    # load up the queue with our dummy input data\n",
        "    enqueue_op = q.enqueue_many(dummy_input)\n",
        "\n",
        "    # now setup a queue runner to handle enqueue_op outside of the main thread asynchronously\n",
        "    qr = tf.train.QueueRunner(q, [enqueue_op] * 1)\n",
        "    # now we need to add qr to the TensorFlow queue runners collection\n",
        "    tf.train.add_queue_runner(qr)\n",
        "\n",
        "    # grab some data out of the queue\n",
        "    data = q.dequeue()\n",
        "    # now print how much is left in the queue\n",
        "    data = tf.Print(data, data=[q.size(), data], message='This is how many items are left in q: ')\n",
        "    # create a fake graph that we can call upon\n",
        "    fg = data + 1\n",
        "    # now run some operations\n",
        "    with tf.Session() as sess:\n",
        "        # we first create a TensorFlow coordinator instance which will handle\n",
        "        # all the asynchronous threads and their interactions\n",
        "        coord = tf.train.Coordinator()\n",
        "        # now we have to start all our queue runners - if we neglect to do this\n",
        "        # the main thread will hang waiting for them to be started\n",
        "        threads = tf.train.start_queue_runners(coord=coord)\n",
        "        # As opposed to the previous function, we don't have to call sess.run(enqueue_op)\n",
        "        # because our queue runner will figure out when this needs to be called.  It\n",
        "        # will do so at the beginning, and also when the queue runs out of values\n",
        "\n",
        "        # now dequeue a few times, and we should see the number of items\n",
        "        # in the queue decrease\n",
        "        sess.run(fg)\n",
        "        sess.run(fg)\n",
        "        sess.run(fg)\n",
        "        # previously the main thread blocked / hung at this point, as it was waiting\n",
        "        # for the queue to be filled.  However, it won't this time around, as we\n",
        "        # now have a queue runner on another thread making sure the queue is\n",
        "        # filled asynchronously\n",
        "        sess.run(fg)\n",
        "        sess.run(fg)\n",
        "        sess.run(fg)\n",
        "        # this will print, but not necessarily after the 6th call of sess.run(fg)\n",
        "        # due to the asynchronous operations\n",
        "        print(\"We're here!\")\n",
        "\n",
        "        # we have to request all threads now stop, then we can join the queue runner\n",
        "        # thread back to the main thread and finish up\n",
        "        coord.request_stop()\n",
        "        coord.join(threads)"
      ],
      "metadata": {
        "id": "VkCPHtmj7VU6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cifar_shuffle_batch():\n",
        "    batch_size = 128\n",
        "    num_threads = 16\n",
        "    # create a list of all our filenames\n",
        "    filename_list = [data_path + 'data_batch_{}.bin'.format(i + 1) for i in range(5)]\n",
        "    # create a filename queue\n",
        "    # file_q = cifar_filename_queue(filename_list)\n",
        "    file_q = tf.train.string_input_producer(filename_list)\n",
        "    # read the data - this contains a FixedLengthRecordReader object which handles the\n",
        "    # de-queueing of the files.  It returns a processed image and label, with shapes\n",
        "    # ready for a convolutional neural network\n",
        "    image, label = read_data(file_q)\n",
        "    # setup minimum number of examples that can remain in the queue after dequeuing before blocking\n",
        "    # occurs (i.e. enqueuing is forced) - the higher the number the better the mixing but\n",
        "    # longer initial load time\n",
        "    min_after_dequeue = 10000\n",
        "    # setup the capacity of the queue - this is based on recommendations by TensorFlow to ensure\n",
        "    # good mixing\n",
        "    capacity = min_after_dequeue + (num_threads + 1) * batch_size\n",
        "    # image_batch, label_batch = cifar_shuffle_queue_batch(image, label, batch_size, num_threads)\n",
        "    image_batch, label_batch = tf.train.shuffle_batch([image, label], batch_size, capacity, min_after_dequeue,\n",
        "                                                      num_threads=num_threads)\n",
        "    # now run the training\n",
        "    cifar_run(image_batch, label_batch)\n"
      ],
      "metadata": {
        "id": "_uYaJY-Y6SBp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cifar_run(image, label):\n",
        "    with tf.Session() as sess:\n",
        "        coord = tf.train.Coordinator()\n",
        "        threads = tf.train.start_queue_runners(coord=coord)\n",
        "        for i in range(5):\n",
        "            image_batch, label_batch = sess.run([image, label])\n",
        "            print(image_batch.shape, label_batch.shape)\n",
        "\n",
        "        coord.request_stop()\n",
        "        coord.join(threads)\n"
      ],
      "metadata": {
        "id": "WjzyMOJu7lAm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cifar_filename_queue(filename_list):\n",
        "    # convert the list to a tensor\n",
        "    string_tensor = tf.convert_to_tensor(filename_list, dtype=tf.string)\n",
        "    # randomize the tensor\n",
        "    tf.random_shuffle(string_tensor)\n",
        "    # create the queue\n",
        "    fq = tf.FIFOQueue(capacity=10, dtypes=tf.string)\n",
        "    # create our enqueue_op for this q\n",
        "    fq_enqueue_op = fq.enqueue_many([string_tensor])\n",
        "    # create a QueueRunner and add to queue runner list\n",
        "    # we only need one thread for this simple queue\n",
        "    tf.train.add_queue_runner(tf.train.QueueRunner(fq, [fq_enqueue_op] * 1))\n",
        "    return fq"
      ],
      "metadata": {
        "id": "sP-DfdCE7m1l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cifar_shuffle_queue_batch(image, label, batch_size, capacity, min_after_dequeue, threads):\n",
        "    tensor_list = [image, label]\n",
        "    dtypes = [tf.float32, tf.int32]\n",
        "    shapes = [image.get_shape(), label.get_shape()]\n",
        "    q = tf.RandomShuffleQueue(capacity=capacity, min_after_dequeue=min_after_dequeue,\n",
        "                              dtypes=dtypes, shapes=shapes)\n",
        "    enqueue_op = q.enqueue(tensor_list)\n",
        "    # add to the queue runner\n",
        "    tf.train.add_queue_runner(tf.train.QueueRunner(q, [enqueue_op] * threads))\n",
        "    # now extract the batch\n",
        "    image_batch, label_batch = q.dequeue_many(batch_size)\n",
        "    return image_batch, label_batch"
      ],
      "metadata": {
        "id": "hxkM9E8y7oTR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def read_data(file_q):\n",
        "    # Code from https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_input.py\n",
        "    class CIFAR10Record(object):\n",
        "        pass\n",
        "\n",
        "    result = CIFAR10Record()\n",
        "\n",
        "    # Dimensions of the images in the CIFAR-10 dataset.\n",
        "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
        "    # input format.\n",
        "    label_bytes = 1  # 2 for CIFAR-100\n",
        "    result.height = 32\n",
        "    result.width = 32\n",
        "    result.depth = 3\n",
        "    image_bytes = result.height * result.width * result.depth\n",
        "    # Every record consists of a label followed by the image, with a\n",
        "    # fixed number of bytes for each.\n",
        "    record_bytes = label_bytes + image_bytes\n",
        "\n",
        "    # Read a record, getting filenames from the filename_queue.  No\n",
        "    # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
        "    # and footer_bytes at their default of 0.\n",
        "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
        "    result.key, value = reader.read(file_q)\n",
        "\n",
        "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
        "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
        "\n",
        "    # The first bytes represent the label, which we convert from uint8->int32.\n",
        "    result.label = tf.cast(\n",
        "        tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
        "\n",
        "    # The remaining bytes after the label represent the image, which we reshape\n",
        "    # from [depth * height * width] to [depth, height, width].\n",
        "    depth_major = tf.reshape(\n",
        "        tf.strided_slice(record_bytes, [label_bytes],\n",
        "                         [label_bytes + image_bytes]),\n",
        "        [result.depth, result.height, result.width])\n",
        "    # Convert from [depth, height, width] to [height, width, depth].\n",
        "    result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
        "\n",
        "    reshaped_image = tf.cast(result.uint8image, tf.float32)\n",
        "\n",
        "    height = 24\n",
        "    width = 24\n",
        "\n",
        "    # Image processing for evaluation.\n",
        "    # Crop the central [height, width] of the image.\n",
        "    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n",
        "                                                           height, width)\n",
        "\n",
        "    # Subtract off the mean and divide by the variance of the pixels.\n",
        "    float_image = tf.image.per_image_standardization(resized_image)\n",
        "\n",
        "    # Set the shapes of tensors.\n",
        "    float_image.set_shape([height, width, 3])\n",
        "    result.label.set_shape([1])\n",
        "\n",
        "    return float_image, result.label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uo8NvPZX7pu_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"C:\\\\Users\\avaco\\Downloads\\cifar-10-batches-bin\\\\\"\n"
      ],
      "metadata": {
        "id": "AmvBQCUh7_Wz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run_opt = 3\n",
        "    if run_opt == 1:\n",
        "        FIFO_queue_demo_no_coord()\n",
        "    elif run_opt == 2:\n",
        "        FIFO_queue_demo_with_coord()\n",
        "    elif run_opt == 3:\n",
        "        cifar_shuffle_batch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NdFU3ICn7sAy",
        "outputId": "c97a2cf6-357c-4153-dc83-de4d01e12d7b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfRangeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1360\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1361\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_6_shuffle_batch_1/random_shuffle_queue' is closed and has insufficient elements (requested 128, current size 0)\n\t [[{{node shuffle_batch_1}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6b94f0e0f305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mFIFO_queue_demo_with_coord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mrun_opt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcifar_shuffle_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-89db153909e9>\u001b[0m in \u001b[0;36mcifar_shuffle_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                                                       num_threads=num_threads)\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# now run the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcifar_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-03a9d754e97d>\u001b[0m in \u001b[0;36mcifar_run\u001b[0;34m(image, label)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1371\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1394\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1396\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: Graph execution error:\n\nDetected at node 'shuffle_batch_1' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-15-6b94f0e0f305>\", line 8, in <module>\n      cifar_shuffle_batch()\n    File \"<ipython-input-4-89db153909e9>\", line 22, in cifar_shuffle_batch\n      num_threads=num_threads)\nNode: 'shuffle_batch_1'\nRandomShuffleQueue '_6_shuffle_batch_1/random_shuffle_queue' is closed and has insufficient elements (requested 128, current size 0)\n\t [[{{node shuffle_batch_1}}]]\n\nOriginal stack trace for 'shuffle_batch_1':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-6b94f0e0f305>\", line 8, in <module>\n    cifar_shuffle_batch()\n  File \"<ipython-input-4-89db153909e9>\", line 22, in cifar_shuffle_batch\n    num_threads=num_threads)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\", line 357, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py\", line 1344, in shuffle_batch\n    name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/input.py\", line 871, in _shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 490, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3572, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 799, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3762, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2133, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKLcvC6674h2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}